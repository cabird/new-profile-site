# Program Merge Conflict Resolution via Neural Transformers

**Abstract**

Collaborative software development is an integral part of the modern software development life cycle, essential to the success of largescale software projects. When multiple developers make concurrent changes around the same lines of code, a merge conflict may occur. Such conflicts stall pull requests and continuous integration pipelines for hours to several days, seriously hurting developer productivity.To address this problem, we introduce MergeBERT, a novel neural program merge framework based on token-level three-way differencing and a transformer encoder model. By exploiting the restricted nature of merge conflict resolutions, we reformulate the task of generating the resolution sequence as a classification task over a set of primitive merge patterns extracted from real-world merge commit data. Our model achieves 63-68% accuracy for merge resolution synthesis, yielding nearly a 3Ã— performance improvement over existing semi-structured, and 2Ã— improvement over neural program merge tools. Finally, we demonstrate that MergeBERT is sufficiently flexible to work with source code files in Java, JavaScript, Type-Script, and C# programming languages. To measure the practical use of MergeBERT, we conduct a user study to evaluate Merge-BERT suggestions with 25 developers from large OSS projects on 122 real-world conflicts they encountered. Results suggest that in practice, MergeBERT resolutions would be accepted at a higher rate than estimated by automatic metrics for precision and accuracy. Additionally, we use participant feedback to identify future avenues for improvement of MergeBERT.

## INTRODUCTION

Collaborative software development relies on version control systems such as git to manage and track changes across a codebase. In most projects, developers work primarily in a branch of a software repository, periodically synchronizing their code changes with the main branch via merges and pull requests (Gousios, "Work practices and challenges in pull-based development: the contributor's perspective"). When multiple developers make concurrent changes to the same line of code, a merge conflict may occur. Merge commits occur frequently, almost 12% of all commits are related to a merge (Ghiotto, "On the nature of merge conflicts: a study of 2,731 open source java projects hosted by github"), and up to 46% of those commits result in conflicts. Resolving merge conflicts is a time-consuming, complicated, and error-prone activity (Bird, "Assessing the value of branches with what-if analysis"). To resolve a conflict, developers must stop their workflow, understand conflicting changes, and identify a correct resolution. The ideal way to resolve a conflict is not always clear, and may require referring to project specification documentation or communicating with their peers about changes (Bird, "Assessing the value of branches with what-if analysis")(Brun, "Proactive detection of collaboration conflicts")(De, "Recommending Participants for Collaborative Merge Sessions")(LuÃ­s, "Improving early detection of software merge conflicts")(Nelson, "The life-cycle of merge conflicts: processes, barriers, and strategies").
Modern version control systems such as git utilize the diff3 algorithm for performing unstructured line-based three-way merge of input files (Smith, "GNU diff3. distributed with GNU diffutils package"). Thus, it is the de facto tool for merging and identifying merge conflicts in software development. This algorithm aligns the two-way diffs of two versions of the code, A and B, with the common base, O, into a sequence of diff "slots". At each slot, a change from either A or B is selected. In cases where both A and B contain changes (relative to O) in the same slot (e.g., on the same line), there is a merge conflict. Standard merge algorithms cannot automatically determine the correct way to merge these conflicting changes. In these cases, developers must manually intervene in order to correctly resolve the conflicting code and complete the merge.
Over the past decade, several approaches have been proposed to improve the detection and automatic resolution of merge conflicts (Apel, "Semistructured Merge in Revision Control Systems")(Brun, "Proactive detection of collaboration conflicts")(Cavalcanti, "Evaluating and improving semistructured merge")(Khan, "Cassandra: Proactive conflict minimization through optimized task scheduling")(LeÃŸenich, "Renaming and shifted code in structured merging: Looking ahead for precision and performance")(Mens, "A state-of-the-art survey on software merging")(Sousa, "Verified three-way program merge")(Zhu, "Conflict resolution for structured merge via version space algebra"). Some approaches use the abstract syntax trees (ASTs) or other representations of the source code to improve conflict resolution (Apel, "Semistructured Merge in Revision Control Systems")(Tavares, "Semistructured merge in JavaScript systems")(Westfechtel, "Structure-oriented merging of revisions of software documents"); others use a data-driven approach which uses deep learning to predict the correct merge (Dinella, "DeepMerge: Learning to merge programs"). Researchers have also developed tools to help developers visualize and navigate the merge conflict resolution process (Shen, "IntelliMerge: a refactoring-aware software merging technique")[?](Unknown, "Scooter Software. 2021. Beyond Compare"), and identified key needs of the developer community for effective tool support (Nelson, "The life-cycle of merge conflicts: processes, barriers, and strategies"). The sheer body of research dedicated to this problem represents a significant amount of time and effort. Despite these advancements, none of these approaches have been widely adopted into practice, and the git textual-based detection algorithm remains one of the most commonly used merging approaches (Nelson, "The life-cycle of merge conflicts: processes, barriers, and strategies").
In an effort to address this, we introduce MergeBERT: a neural program merge framework based on token-level three-way differencing and a multi-input variant of the bidirectional transformer encoder (BERT) model (Devlin, "BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding"). We formulate the task of generating a merge conflict resolution sequence as a classification task over a set of primitive merge patterns extracted from real-world merge commit data. MergeBERT encodes all inputs that a standard diff3 algorithm takes (two two-way diffs of input programs) as well as the edit sequence information, then aggregates them for learning. We train and then evaluate MergeBERT on 220,000 and 54,000 (respectively) real world historical merge conflicts and their associated manual resolutions from 100,000 GitHub repositories in JavaScript, TypeScript, Java and C#, and find that it performs quite well, with precision and accuracy always over 60% (over 70% if the top three suggestions are considered). Further, we compare MergeBERT to existing state of the art structured and semi-structured merge approaches (which are necessarily language-specific) and show that MergeBERT is able to provide resolution suggestions for more merge conflicts and the suggestions are correct (i.e., match the historical user manual resolution) more often.
To better evaluate the resolutions generated by MergeBERT from users' perspective in practice, we also conduct a user study with 25 developers from large OSS projects. We ask participants to evaluate if MergeBERT resolution suggestions are acceptable on a set of 122 of their own real-world conflicts. Results show that MergeBERT merge resolutions would be accepted in practice despite not always being syntactically identical to the historical user resolutions, and we identify potential ways to improve MergeBERT and the merge conflict oracles used to evaluate neural program merge approaches.
We make the following contributions in this paper:
(1) We introduce MergeBERT, a novel transformer-based program merge framework that leverages token-level three-way differencing and formulates the task of generating the resolution sequence as a classification task. (Apel, "Structured merge with auto-tuning: balancing precision and performance") We evaluate MergeBERT against structured and semi-structured program merge tools like JSFSTMERGE and JDIME, as well as neural program merge models (Dinella, "DeepMerge: Learning to merge programs"). We demonstrate that MergeBERT outperforms the state-of-the-art, achieving 2-3Ã— higher accuracy on merge resolution. (3) We present an empirical evaluation of the perceptions of MergeBERT resolutions with 25 developers from large OSS projects, contributing the first user study in which developers use and evaluate an automatic merge conflict resolution tool on their own real-world conflicts.
We make available an online data package (Unknown, "Online Data Set for Program Merge Conflict Resolution via Neural Transformers") containing the test dataset of conflicts and user resolutions, as well as, the questions and responses gathered from our user study. We also provide an online Appendix with supplementary details and figures (Unknown, "Authors Elided for Review") (also uploaded with this submission).

## MOTIVATING EXAMPLE

We use a number of terms, concepts, and ideas throughout this paper. To provide an intuition around how our approach works and concretely define terms and concepts, we begin with a motivating example of a small, but realistic merge conflict.
Fig. 1 provides an example merge conflict in JavaScript which shows the result of merging two concurrent changes to the same JavaScript file. Fig. 1(a) on the left shows the standard diff3 markers "<<<<<<< A.js", "||||||| O.js", "=======" and ">>>>>>> B.js", which demarcate the conflicting regions introduced by programs A, base O, and B respectively. Here, O represents the lowest common ancestor of programs A and B in the version control history. We denote the program text of diff3 conflicting regions as ğ´, ğµ, ğ‘‚. The program text outside the conflicting regions -prefix and suffix -is common to all three programs versions. Normally conflicts files have the same name in different branches, but to avoid confusion, we name the original file in our example O.js, and the two concurrently edited versions of this file A.js and B.js. A.js changes "var x" to "let x" and the 10 to 11, while B.js changes the 10 to 11 and also adds an argument z.
MergeBERT attempts to automatically resolve merge conflicts in two phases. First, MergeBERT represents each line-level merge conflict instance at the token level which localizes conflicting regions. Intuitively, MergeBERT converts the three line-structured source texts into three sequences of tokens (including space and line delimiters), applies the standard diff3 algorithm to these token sequences, and then reconstructs the merged document at line level. Fig. [?] shows the result of applying this token-level merge on Fig. 1(a). As a result of token-level merge, the whole "let x = max(y," string is cleanly merged, becoming a part of the program prefix, and ")" is prepended to the program suffix. Second, Merge-BERT invokes an underlying neural model to suggest a resolution via classification for each token-level conflicting region and replaces the conflict region with the suggestion from the model (Fig. 1(c)).
Observe that the resolution does not consist of any single line from either ğ´ or ğµ since both edits modify a common line in the base. Hence, earlier neural approaches such as DeepMerge (Dinella, "DeepMerge: Learning to merge programs") that are restricted to picking entire lines from the conflict region would not be able to provide the resolution. On the other hand, structured merge techniques (such as JSFSTMERGEby (Tavares, "Semistructured Merge in JavaScript Systems")) cannot resolve the conflict soundly as the conflict appears on a program statement, which leads to side effects (e.g. syntactically incorrect code).
A token-level merge can interleave edits within lines (i.e., tokens in which one edit does not conflict with another are trivially merged). Consider A's edit of the var to let keyword. Such non-conflicting edits suffice to demonstrate the above. Token-level diff3 is a syntactic merge algorithm and therefore cannot guarantee semantic or even syntactic correctness of the merged program. However, we observed that in practice, syntactic correctness is preserved the majority of the time (over 97%).
Likewise, consider the token-level conflict for the max function's arguments: an appropriate model trained on JavaScript should easily deduce that taking the edit from B (i.e., "11, z") captures the behavior of A's edit as well. The suggested resolution gives an intuitive demonstration of how MergeBERT turns a complex line-level resolution into a simpler token-level classification problem.

## BACKGROUND: DATA-DRIVEN MERGE

Dinella et al. [15] introduced the data-driven program merge problem as a supervised machine learning problem. A program merge consists of a 4-tuple of programs (A, B, O, M), where (1) The base program O is the lowest common ancestor in the version history for programs A and B, (2) diff3 produces an unstructured line-level conflict when applied to (A, B, O), and (3) M is the merged program with the developer resolution, incorporating changes made in A and B. A merge may have multiple unstructured conflicts, we define a merge tuple (ğ´, ğµ, ğ‘‚, ğ‘€), where ğ´, ğµ, ğ‘‚ correspond to the conflicting regions in (A, B, and O), respectively, and ğ‘€ denotes the resolution region. Given a set of merge tuples (ğ´ ğ‘– , ğµ ğ‘– , ğ‘‚ ğ‘– , ğ‘€ ğ‘– ), i = 0...N, the goal of a data-driven merge algorithm is to learn a function, merge, that maximizes ğ‘ ğ‘–=0 merge(ğ´ ğ‘– , ğµ ğ‘– , ğ‘‚ ğ‘– ) = ğ‘€ ğ‘– .
Throughout the text, we will use notations (ğ‘, ğ‘, ğ‘œ, ğ‘š) to refer to the token-level merge tuples.
Dinella et al. (Dinella, "DeepMerge: Learning to merge programs") also provide an algorithm for extracting the exact resolution regions for each merge tuple and define a dataset that corresponds to non-trivial resolutions; resolutions where the developer does not drop the changes from one side of the merge. Further, they provide a sequence-to-sequence encoder-decoder based architecture, where a bi-directional gated recurrent unit (GRU) is used for encoding the merge inputs comprising of (ğ´, ğµ, ğ‘‚) segments of a merge tuple, and a pointer mechanism is used to restrict the output to only choose from line segments present in the input. Their paper suffers from two limitations. First, given the restriction on copying only lines from inputs, their dataset did not consider merges where the resolution required token-level interleaving, such as the conflict in Figure 1. Second, their dataset consists of merge conflicts in a single language, namely JavaScript. Our approach addresses both of these limitations.

## MERGE CONFLICT RESOLUTION AS A CLASSIFICATION TASK

In this work, we demonstrate how to exploit the restricted nature of merge conflict resolutions -compared to an arbitrary program repairto leverage discriminative models to synthesize the merge resolution sequence. We have empirically observed that the application of diff3 at token granularity enjoys two useful properties over its line-level counterpart: (i) it helps localize the merge conflicts to small program segments, effectively reducing the size of conflicting regions, and (ii) most resolutions of merge conflicts produced by token diff3 consist entirely of changes from ğ‘ or ğ‘ or ğ‘œ or a sequential composition of ğ‘ followed by ğ‘ or vice versa. Here, and throughout the paper we will use lower case notations to refer to attributes of token-level differencing (e.g. ğ‘, ğ‘, and ğ‘œ are conflict regions produced by diff3 at token granularity). On the flip side, a token-level merge can introduce many small conflicts. To balance the trade-off, we start with the line-level conflicts as produced by the standard diff3 and perform a token-level merge of only the segments present in the line-level conflict. There are several potential outcomes for such a two-level merge at the line-level:
â€¢ A conflict-free token-level merge: For example, the edit from ğ´ about let is merged since ğµ does not edit that slot as shown in Fig. 1(b). â€¢ A single localized token-level merge conflict: For example, the edit from both ğ´ and ğµ for the arguments of max yields a single conflict as shown in Fig. 1(b).
â€¢ Multiple token-level conflicts: Such a case (not illustrated above) can result in several token-level conflicts.
let x = max(y, <<<<<<< branch A 11 ||||||| 10 ======= branch O 11, z >>>>>>> branch B ) Classification Encoder Aggregation Embedding Token = = = = â†” = = = x = max ( , 11 ) y = x max ( 10 ) y , = x max y 10 ) , ( = = = = = = â†” + + = x = max ( y , 11 , z ) Resolution Decoding A Edit let x = max(y, 11, z) O B Encoder Encoder Encoder Position Embedding Token Edit Position Embedding Token Edit Position Embedding Token Edit Position We extract edit steps for each pair of token sequences (âˆ† ğ‘ğ‘œ and âˆ† ğ‘ğ‘œ ). Four aligned token sequences are fed to the multi-input encoder neural network, while edit sequences are consumed as edit type embeddings. Finally, encoded token sequences are aggregated into a hidden state which serves as input to classification layer.
Token-level diff3 applied to a 4-tuple of programs (A, B, O, M), would usually result in a set of localized merge tuples âŸ¨ğ‘ ğ‘— , ğ‘ ğ‘— , ğ‘œ ğ‘— , ğ‘š ğ‘— âŸ©. We empirically observe that 74% of such resolutions ğ‘š ğ‘— are comprised of (ğ‘–) exactly the tokens in ğ‘ ğ‘— or (ğ‘–ğ‘–) exactly the tokens in ğ‘ ğ‘— . Another 0.4% of the resolutions are (ğ‘–ğ‘–ğ‘–) just the tokens in ğ‘œ ğ‘— . In addition, 23% of the resolutions are the result of concatenating (ğ‘–ğ‘£) ğ‘ ğ‘— and ğ‘ ğ‘— or (ğ‘£) ğ‘ ğ‘— and ğ‘ ğ‘— . Finally, 1.8% comprise another four variants, obtained by taking ğ‘–, ğ‘–ğ‘–, ğ‘–ğ‘£ and ğ‘£ above and removing the tokens that also occur in the base, ğ‘œ ğ‘— . In total, this provides nine primitive merge resolution patterns (see online Appendix (Unknown, "Authors Elided for Review") for more details about the primitive merge patterns).
We, therefore, treat the problem of constructing merge conflict resolutions ğ‘š ğ‘— as a classification task to predict between these possibilities. It is important to note that although we are predicting simple resolution strategies at the token-level, they may translate to complex resolutions at the line-level. In addition, not all conflicts are resolved by breaking that conflict into tokens and applying these patterns-some resolutions such as those introducing new tokens or reordering tokens are not expressible as a choice at the token-level.

## MERGEBERT: NEURAL PROGRAM MERGE FRAMEWORK

MergeBERT is a textual program merge model based on the bidirectional transformer encoder (BERT) model (Devlin, "BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding"). We refer the reader to CodeBERT (Feng, "CodeBERT: A Pre-Trained Model for Programming and Natural Languages") for a discussion on applying transformers to code. A transformer, like a recurrent neural network, maps a sequence of text into a high dimensional representation, which can later be decoded to solve downstream tasks. While not originally designed for code, transformers have found many applications in software engineering (Clement, "Multi-mode Translation of Natural Language and Python Code with Transformers")(Kanade, "Learning and evaluating contextual embedding of source code")(Svyatkovskiy, "Intellicode compose: Code generation using transformer") MergeBERT approaches merge conflict resolution as a sequence classification task given conflicting regions extracted with tokenlevel differencing and surrounding code as context. The key technical innovation in MergeBERT lies in how it breaks program text into an input representation amenable to learning with a transformer encoder and how it aggregates various input encodings for classification.
In the standard sequence learning setting there is a single input and single output sequence. In the merge conflict resolution task, there are multiple conflicting input programs and one resolution. To facilitate learning in this setting, we construct MergeBERT as a multi-input encoder neural network, which first encodes token sequences of conflicting programs, then aggregates them into a single hidden summarization state.
An overview of the MergeBERT model architecture is shown in Fig. 2. Given conflicting programs A, B and O we first perform tokenization and then repeat the three-way differencing at token granularity. If a conflict still exists in this token-level three-way differencing, we collect the token sequences corresponding to conflicting regions ğ‘, ğ‘, and ğ‘œ, and compute pair-wise alignments of ğ‘ and ğ‘ with respect to the base ğ‘œ. Finally, for each pair of aligned token sequences we extract an "edit sequence" that represents how to turn the second sequence into the first. The resulting aligned token sequences are fed to the multi-input encoder neural network, while the corresponding edit sequences are consumed as type embeddings. Finally, the encoded token sequences are summarized into a hidden state which serves as input to the classification layer.
Given a 4-tuple of programs (A, B, O, M) which contains tokenlevel merge tuples (ğ‘ ğ‘— , ğ‘ ğ‘— , ğ‘œ ğ‘— , ğ‘š ğ‘— ), j=0...N, MergeBERT models the following conditional probability distribution:
and consequently, for entire programs:
) Independence of token-level conflicts is a simplifying assumption. However, we observe that in our data set only 5% of merge conflicts result in more than 1 token-level conflict per line-level conflict.

## Context Encoding

For a merge tuple (ğ‘, ğ‘, ğ‘œ, ğ‘š) MergeBERT calculates two pair-wise alignments between the sequences of tokens of conflicting regions ğ‘ (respectively ğ‘) with respect to that of the original program ğ‘œ: ğ‘| ğ‘œ , ğ‘œ | ğ‘ , ğ‘ | ğ‘œ , and ğ‘œ | ğ‘ . For each pair of aligned token sequences we compute an edit sequence. These edit sequences -âˆ† ğ‘ğ‘œ and âˆ† ğ‘ğ‘œare comprised of the following editing actions (kinds of edits): = represents equivalent tokens, + represents insertions,represents deletions, â†” represents a replacement, and âˆ… is used as a padding token. Overall, this produces four token sequences and two edit sequences: (ğ‘| ğ‘œ , ğ‘œ | ğ‘ , and âˆ† ğ‘ğ‘œ ) and (ğ‘ | ğ‘œ , ğ‘œ | ğ‘ , and âˆ† ğ‘ğ‘œ ). Fig. 3 provides an example of an edit sequence. Each token sequence covers the corresponding conflicting region and, potentially, surrounding code tokens. We make use of Byte-Pair Encoding (BPE) unsupervised tokenization to avoid a blowup in the vocabulary size given the sparse nature of code identifiers (Karampatsis, "Big Code Ì¸ = Big Vocabulary: Open-Vocabulary Models for Source Code"). To help the model learn to recognize editing steps we introduce an edit type embedding. We combine it with the standard token and position embeddings utilized in BERT model architecture via addition.

## Merge Tuple Aggregation

We utilize transformer encoder model E to independently encode each of the four token sequences of token-level conflicting regions ğ‘| ğ‘œ , ğ‘œ | ğ‘ , ğ‘ | ğ‘œ , and ğ‘œ | ğ‘ , passing corresponding edit sequences âˆ† ğ‘ğ‘œ and âˆ† ğ‘ğ‘œ as type embeddings. Finally, MergeBERT aggregates the resulting encodings into a single hidden summarization state â„:
where E(ğ‘¥, âˆ† ğ‘¥ ) are the encoded tensors for each of the sequences ğ‘¥ âˆˆ (ğ‘| ğ‘œ , ğ‘œ | ğ‘ , ğ‘ | ğ‘œ , ğ‘œ | ğ‘ ), and ğœƒ ğ‘¥ are learnable weights. After aggregation a linear classification layer with softmax is applied:
The resulting line-level resolution region is obtained by concatenating the prefix, predicted token-level resolution ğ‘š ğ‘— , and the suffix. Finally, in the case of a one-to-many correspondence between the original line-level and the token-level conflicts (see Appendix for more details and a pseudocode), MergeBERT uses a standard beamsearch to decode the most promising predictions.

## Implementation Details

We utilize a pretrained CodeBERTfoot_0 model with 6 encoder layers, 12 attention heads, and a hidden state size of 768. The vocabulary is constructed using byte-pair encoding (Sennrich, "Neural Machine Translation of Rare Words with Subword Units") and the vocabulary size is 50000. We transfer the weights of the pretrained transformer encoder into the MergeBERT multi-input neural network, and attach a randomly initialized linear layer with softmax. We then finetune the resulting neural network in a supervised setting for the sequence classification task. Input sequences for finetuning training cover conflicting regions and surrounding code (i.e., fragments of prefix and suffix of a conflicting region) up to a maximum length of 512 BPE tokens. The backbone of our implementation is HuggingFace's 2RobertaModel and RobertaForSequenceClassification classes in PyTorch, which are modified to turn the model into a multi-input architecture shown in Fig. 2. We finetune MergeBERT with Adam stochastic optimizer with weight decay fix using a learning rate of 5e-5, 512 batch size and 8 backward passes per allreduce. The finetuning training was performed on 4 NVIDIA Tesla V100 GPUs with 16GB memory for 6 hours.
In the inference phase, the model prediction for each line-level conflict consists of one or more token-level predictions. Given the token-level predictions and the contents of the merged file, Merge-BERT generates the code corresponding to the resolution region. The contents of the merged file include the conflict in question and its surrounding regions. Afterward, MergeBERT checks the syntax of the generated code with a tree-sitterfoot_2 parser and outputs it as the candidate merge conflict resolution only if it is syntactically correct.

## RESEARCH QUESTIONS

We pose the following research questions to evaluate the effectiveness of utility of MergeBERT. RQ1: How effective is MergeBERT in producing merge conflict resolutions? We evaluate MergeBERT's performance of producting resolutions in terms of precision and accuracy of matching the actual user resolution extracted from real-world merge resolutions. We also provide a comparison MergeBERT to baseline approaches (at both the line and token level) and state of the art merge resolution approaches. RQ2: How well does MergeBERT perform across different languages? One of our primary goals is to be able to work on multiple languages with minimal effort. The core approach of MergeBERT is fundamentally language agnostic (though a parser and tokenizer is required for each additional language). We evaluate performance of MergeBERT across four languages and also compare the results of using four language-specific models (each trained on just one language) to using one multi-lingual model trained on the data from all four languages. RQ3: How do different choices of context encoding impact performance of MergeBERT? We conduct an ablation study of the edit type embedding to understand and evaluate the impact of our novel edit-aware encoding on model performance. RQ4: How do users perceive MergeBERT resolutions? We conduct a user study involving a survey of real-world conflicts recently encountered by developers from large OSS projects. To understand how developers would use MergeBERT in practice, we provide them with an interface to explore MergeBERT's conflict resolution suggestions in relation to their original conflicting code ask them evaluate suggestions and explain why they do or do not correctly resolve the merge conflict.

## DATASET

The finetuning dataset is mined from over 100,000 open source software repositories in multiple programming languages with merge conflicts. It contains commits from git histories with exactly two parents, which resulted in a merge conflict. We replay git merge on the two parents to see if it generates any conflicts. Otherwise, we ignore the merge from our dataset. We use the approach introduced by Dinella et al. (Dinella, "DeepMerge: Learning to merge programs") to extract resolution regions-however, we do not restrict ourselves to conflicts with less than 30 lines only. Lastly, we extract token-level conflicts and conflict resolution classification labels (introduced in Section 4) from line-level conflicts and resolutions. Tab. 1 provides a summary of the finetuning dataset.

## EVALUATION 8.1 Evaluation Metrics

We evaluate MergeBERT's performance of resolution synthesis in terms of precision and accuracy of string match (modulo whitespaces or indentation) to the user resolution extracted from real-world historical merge resolutions. This approach is rather restrictive as a suggested resolution might differ from the actual user resolution by, for instance, only the order of statements, being semantically equivalent otherwise. As such, this evaluation approach gives a lower bound of performance.
We evaluate MergeBERT and compare it to baselines and existing approaches using two metrics, precision at top-k and accuracy at top-k. Since MergeBERT is a neural approach, it may provide more than one suggestion, which we rank according to the associated prediction probabilities. In addition, because we filter out resolution suggestions that are not syntactically valid, it may provide no suggestions in rare cases. Accuracy at top-1 indicates the percentage of total conflicts for which MergeBERT produces the correct resolution as its top suggestion. Precision at top-1 indicates how often (as a percentage) the top suggestion is correct when the MergeBERT provides any suggestions at all. As a concrete example, if a tool produces a resolution suggestion for 50 out of 100 conflicts and 40 of the suggestions matched the actual historical user resolution, then the precision would be 80% (40/50), but the accuracy would be 40% (40/100). Precision at top-k indicates how often the correct resolution is found in the top-k suggestions and Accuracy at top-k is analogous. When "top-k" is omitted from the metric name (e.g. just "Precision") then k is 1.

## Baseline Models

8.2.1 Language Model Baseline. Neural language models (LMs) have shown great performance in natural language generation (Radford, "Language Models are Unsupervised Multitask Learners")(Sellam, "BLEURT: Learning Robust Metrics for Text Generation"), and have been successfully applied to the domain of source code (Feng, "CodeBERT: A Pre-Trained Model for Programming and Natural Languages")(Hindle, "On the Naturalness of Software")(Svyatkovskiy, "IntelliCode Compose: Code Generation Using Transformer"). We consider the generative pretrained transformer language model for code (GPT-C) and appeal to the naturalness of software (Allamanis, "A Survey of Machine Learning for Big Code and Naturalness") to construct our baseline approach for the merge resolution synthesis task. We establish the following baseline: given an unstructured line-level conflict produced by diff3, we take the common source code prefix acting as user intent for program merge. We attempt to generate an entire resolution region token-by-token using beam search. As an ablation experiment, we repeat this for the conflicts produced with the token-level differencing algorithm (Fig. 1 shows details about prefix and conflicting regions).

## DeepMerge:

Neural Model for Interleavings. Next, we consider DEEPMERGE (Dinella, "DeepMerge: Learning to merge programs"): a sequence-to-sequence model based on the bidirectional GRU summarized in section 3. It learns to generate a resolution region by choosing from line segments present in the input (line interleavings) with a pointer mechanism. We retrain the DEEPMERGE model on our TypeScript dataset.

## JDIME.

Looking for a stronger baseline, we consider JDIME, a Java-specific merge tool that automatically tunes the merging process by switching between structured and unstructured merge algorithms (Apel, "Structured merge with auto-tuning: balancing precision and performance"). Structured merge is abstract syntax tree (AST) aware and leverages syntactic information to improve matching precision of conflicting nodes. We use the publicly available implementation (Jdime, "JDime Publicly Available Implementation"), and run JDime in semi-structured mode. 8.2.4 jsFSTMerge. Trindade Tavares et al. (Tavares, "Semistructured Merge in JavaScript Systems") implemented JS-FSTMERGE by adapting an off-the-shelf grammar for JavaScript to address shortcomings of FSTMERGE (Apel, "Semistructured Merge: Rethinking Merge in Revision Control Systems") and modify its algorithm. JSFSTMERGE allows for certain types of nodes to maintain their relative order (e.g., statements) while others may be order independent (e.g., function declarations) even when sharing the same parent node. For cases where JSFSTMERGE produces a resolution not matching the user resolution, we manually inspect the output for semantic equivalence (e.g., reordered import statements).

## Results

## RQ1: How effective is MergeBERT in producing merge conflict resolutions?

To evaluate MergeBERT We first compare it to other neural approaches and to diff3. To be comprehensive, we evaluate at both the token level and the line level. We then compare MergeBERT to existing state of the art structured and semi-structured merge language-specific merge approaches. As seen in Tab. 2, language model baselines' performance on merge resolution synthesis is relatively low, suggesting that the naturalness hypothesis is insufficient to capture the developer intent when merging programs. This is perhaps not surprising given the notion of precision that does not tolerate even a single token mismatch.
MergeBERT is based on two core components: token-level diff3 and a multi-input neural transformer model. The token-level differencing algorithm alone gives a high top-1 precision of 82.4%, with a relatively low accuracy of only 36.1% (i.e., it doesn't always generate a resolution suggestion, but when it does, it is very often correct). Combined with the neural transformer model, the accuracy is increased to a total of 68.2%. Note, as a deterministic algorithm token-level diff3 can only provide a single suggestion.
DeepMerge precision of merge resolution synthesis is quite admirable, showing 55.0% top-1 precision. However, it fails to generate predictions for merge conflicts which are not representable as a line interleaving. This type of merge conflict comprises only roughly one third of the test set, resulting in an accuracy of only 35.1% which is significantly lower than MergeBERT.
As an experiment, we also evaluate the DeepMerge model in combination with the token-level diff3. This enables DeepMerge to overcome the limitation of providing only resolutions comprised of interleavings of lines from the conflict region by interleaving tokens instead. As seen in Tab. 2 (DeepMerge with Token granularity) overall accuracy improves from 35.1% to 42.7%. However this still falls short of MergeBERT with precision that is 5% less (64.5% vs. 69.1%) and accuracy that is 25% less (42.7% vs 68.2%).
We also compared MergeBERT to state of the art structured and semi-structured merge tools. Since both JDIME and JSFSTMERGE are language-specific, to compare against MergeBERT, we use our dataset's corresponding language-specific subset of conflicts (leading to slightly different results for MergeBERT on Java and JavaScript).
As can be seen from Tab. 3, JSFSTMERGE only produces a resolution for 22.8% of conflicts and when a resolution is produced by JSFSTMERGE, it is only correct 15.8% of the time, yielding a total accuracy of 3.6%. This is in line with the conclusions of the creators of JSFSTMERGE that semi-structured merge approaches may not be as advantageous for dynamic scripting languages (Tavares, "Semistructured Merge in JavaScript Systems"). Because JSF-STMERGE may produce reformatted code, we manually examined cases where a resolution was produced but did not match the user resolution (our oracle). If the produced resolution was semantically equivalent to the user resolution, we classified it as correct.
To compare the accuracy of JDIME to that of MergeBERT, we use the Java Test data set introduced previously and complete the following evaluation steps: JDIME does not merge all conflicts and generates a resolution for 82.1% of conflicts. This is in line with related work reporting that as much as 21% of files cannot be merged (Apel, "Structured merge with auto-tuning: balancing precision and performance"). Therefore, first, we identify the set of merge conflict scenarios where diff3 reports a conflict and JDIME produces a non-conflicted merge. When comparing the JDIME output to the actual historical user-performed merge conflict resolution, we do not use a simple syntactic match. As a result of its AST matching approach, code generated by JDIME is reformatted, and the original order of statements and other constructs are not always preserved. In an effort to accurately and fairly identify semantically equivalent merges, we use GumTree (Falleri, "Fine-grained and accurate source code differencing"), an AST differencing tool, to identify and ignore semantically equivalent differences between JDIME output and the user resolution, such as reordered method declarations. When JDIME produces a resolution, it generates a semantically equivalent match 26.3% of the time, with an accuracy of 21.6%. RQ2: How well does MergeBERT perform across different languages? One goal of our approach is to be able to handle multiple languages with minimal effort. For MergeBERT to be able to provide merge resolution suggestions for conflicts in a particular language, it needs three things. First, a tokenizer in that language, which allows us to split the source text into tokens for processing. Second, a parser in that language, which allows us to filter out syntactically incorrect merge resolution suggestions. Third, a data set of merge conflicts and their user-resolutions to train MergeBERT. Fortunately, tokenizers and parsers for nearly any language are readily available (e.g., we use GitHub's tree-sitter for this) and repositories that use a particular language can be easily identified (e.g. on GitHub) and mined for conflicts and resolutions.
We incorporated tokenizers and parsers into MergeBERT for JavaScript, TypeScript, Java, and C# and gathered merge conflict data for these languages as described previously. Note that both comments and strings in these languages are represented as single tokens and can be quite long. Therefore we further split these tokens on whitespace. Tab. 4 shows the detailed evaluation results of MergeBERT broken down by language. The top section of results shows performance when MergeBERT is trained on data for that specific language. The bottom section shows performance for each language when MergeBERT is trained on a data set comprising data for all languages (we term this the multilingual model). Note that for the language specific models, performance is fairly consistent across all four languages with Top-1 precision ranging from 63.9% to 69.1% and Top-1 Accuracy ranging from 63.2% to 68.2%. We also find that over 97% of MergeBERT suggestions are syntactically correct across all programming languages. We had no a priori expectations of the performance of the multilingual model, as it is trained on more data, which could lead to improvement, but it is not language specific, which could lead to poorer results. Overall, the multilingual variant of the model generates results that are just slightly below the monolingual versions. Thus performance on one language isn't improved by adding more data in other languages. Thus, from a pragmatic perspective, if one chooses to simplify their use of MergeBERT by training just one model instead of one model per language, then the performance takes only a negligible hit.

## RQ3: How do different choices of context encoding impact performance of MergeBERT?

We conduct an ablation study on the edit type embedding to understand the impact of edit-awareness of encoding on the model performance. As shown in Tab. 5, use of the edit type embedding improves MergeBERT from 63% to 68%.

## USER EVALUATION 9.1 User Study Design

To better understand how MergeBERT performs in practice, we ask developers about conflicts that MergeBERT is unable to correctly resolve. Since MergeBERT's resolution suggestions are evaluated against user resolutions using a verbatim string match (modulo whitespace), asking study participants to confirm identical resolutions predicted by MergeBERT is not informative. Therefore, we extract conflicts where MergeBERT suggestions are not a direct match to the user resolution to determine what the limitations of the suggestions are, and how they might be perceived in practice.
To build an oracle of merge conflicts and resolutions we identify 8 open source projects hosted on GitHub. The selected projects are active, with multiple contributors, and contain a large number of conflict scenarios in one of the languages supported by MergeBERT. Tab. 6 contains a list of projects chosen. For each project, we follow the same steps outlined in Section 7 to extract candidate conflicts and user resolutions to use in the survey.
Fig. 4 explains the methodology used to identify candidate merge conflicts. We identify the set of conflicts MergeBERT is unable to correctly merge (within the top-3 suggestions). From this set of conflicts, we identify candidate conflicts to use as part of the user study. We filter candidate files with the following criteria:
(1) Conflicts should have been recently resolved i.e., at most within the past 12 months. Participants may not retain the context needed to evaluate suggestions for older conflicts.
(2) Files must have at most 4 conflicts. Participants evaluate up to 3 suggestions per conflict. More conflicts may be too complex to evaluate within the interview time slot. (3) Conflicts should be non-trivial. Trivial conflicts, such as those that only involve formatting changes or renames, are manually excluded. The determination of if a conflict was non-trivial was manual and subjective, informed by our belief that more substantive conflicts would lead to more insights in the user study.
For each candidate conflict identified, we use the GitHub API to identify authors for each of the conflicting branches and the resolved file. Authors with at least 3 candidate merge conflicts are identified as potential survey participants. Our final pool of candidate participants consists of 52 unique authors. We recruit participants via email, using contact information on GitHub. Out of the 52 contacted developers, 25 agreed to participate in the study. All participants were professional software developers with at least 2-8 years of experience working at large technology companies. We asked participants to evaluate MergeBERT resolution suggestions for their own merge conflicts. Tab. 6 contains the final number of participants and conflicts evaluated in our study. 122 conflicts were evaluated: 32 C# conflicts, 30 Java, and 60 Typescript. 9.1.1 MergeBERT Interface. We designed an online interface where participants can view their own conflicts and explore Merge-BERT's resolution suggestions. Participants are asked to evaluate their own recently resolved merge conflicts, and the corresponding generated resolution suggestions by MergeBERT. The interface is customized based on the signed-in participant and displays a list of their recently encountered merge conflicts. Participants can click through different resolution suggestions to evaluate if they are acceptable ways to resolve the merge conflict. They can view their original resolution on the same page, and if needed, participants can navigate to the conflicting commit on GitHub using a link if they need additional context. They can also view a diff between the conflict file and any of the selected options (resolution suggestion or user resolution). Participants use this interface to select one or more of the suggested resolutions, indicate if the suggested resolution is acceptable, and explain the reasons why or why not. Our online data package (Unknown, "Online Data Set for Program Merge Conflict Resolution via Neural Transformers") and appendix (Unknown, "Authors Elided for Review") contain the questions, images of the interface, and participant responses. 9.1.2 Protocol. The user study was conducted as 30 minute interviews remotely over Microsoft Teams using the interface we built. First, participants watched a video explaining MergeBERT and how to navigate conflicts and evaluate resolution suggestions using the interface. Then, the participants evaluated a set of conflicts and submitted their responses. One of the authors was on the teams call to help participants navigate the interface and ask any clarifying questions based on their evaluation of the MergeBERT resolution suggestions. Questions were iteratively developed based on two pilot interviews. Each interview was recorded for transcription and analysis.

## User Study Results

## RQ4: How do users perceive MergeBERT resolutions?

Using the interface participants evaluate the conflict resolution suggestions generated by MergeBERT and indicate if any of the suggestions were acceptable, and explain why or why not. There were no noticeable differences in the participants' responses across different languages or projects so we do not break down our results by those dimensions. Participant's evaluations of the merge suggestions generally fall into three categories: 1) the merge suggestion is correct and would be used to resolve the conflict 2) the merge is incorrect but the correct resolution would require an understanding of external context and 3) the merge is incorrect and no external context is needed. 9.2.1 Acceptable Merge Suggestions. Surprisingly, of the 122 conflicts included in the study, participants indicated that at least one of the 3 suggestions generated by MergeBERT was correct for 54% (66/122) of the examples. By design, the suggestions presented in the study are not syntactically equivalent to the participant's original resolution, however, they still indicated that the suggestion was a correct merge. Using participant responses, we identify a few reasons why merge suggestions may be acceptable to a developer, even if it is not syntactically equivalent to their original resolution:
Semantically Equivalent Resolution (54 of 122 conflicts) Semantically equivalent resolutions include scenarios where the statements are re-ordered, equivalent changes made to naming or documentation, and unneeded import statements or commented out code is preserved or removed.
One example in the study of conflicting changes that are both equally acceptable, and one is arbitrarily accepted by the resolving author is when authors of conflicting branches renamed the same variable with a slight variation: SPAN_TARGET_ATTRIBUTE_NAME and SPAN_TARGET_APP_ID_ATTRIBUTE_NAME. In these cases, either version selected by the merging algorithm might still be acceptable to the developer. MERGEBERT generated a suggestion to keep the variable name SPAN_TARGET_ATTRIBUTE_NAME whereas the user resolution originally kept the other. Participant P5 marked this resolution as acceptable and semantically equivalent, explaining that in this scenario they had 'no preference as to which one is better'.
Takeaway 1: Evaluating the performance of MergeBERT using strict syntactic approaches estimates a lower bound of performance. Survey results show almost 45% of MergeBERT suggestions are acceptable merges that are semantically equivalent to the participant's original resolution. MergeBERT's performance could be improved by considering semantic information, for example, to identify how changes related to naming or documentation should be merged.
Tangled Code Changes in Oracle (10/122) Resolutions for 10 of the conflicts contained additional "tangled" changes (Herzig, "The Impact of Tangled Code Changes")(Kirinuki, "Hey! Are You Committing Tangled Changes?") that were unrelated to the resolution. Examples include renaming a method and adding a variable in the conflict region that is then used later outside the conflict region. In all 10 instances, MERGEBERT generates a suggestion that does not include the additional tangled code, but is acceptable to the participant as a resolution of the conflict. Participants indicated that if they had access to the MERGEBERT suggestions, they would select the correct resolution and then manually add the additional code.
Takeaway 2: When committing merged code, developers may introduce changes unrelated to the conflict which are inadvertently included in conflict resolution oracles. These changes can negatively impact model performance estimated with automatic metrics. 9.2.2 Merge Requires External Context. MERGEBERT did not generate an acceptable suggestion for 46% (56/122) of examples shown to survey participants. Participants were asked to indicate whether they resolved these examples using external context that cannot be inferred from the conflicting code regions and to explain what the external context was. Results indicate that 16% (20/122) of conflicts in the survey sample require external information not found in either conflicting file, in order to be correctly resolved. One example of external context is knowledge of linter rules enabled at a project level. Projects often require linter checks before code can be committed to the repository, as a step towards improving the quality and maintainability of the source code. One example is a merge conflict from Roslyn where the correct resolution was to remove a null check from the code. Participant P23 explained the decision to remove the check: "The previousResults parameter is non-nullable because C# nullability checking is now enabled at the project level. The null check is unnecessary". In this scenario, without specific knowledge of linter checks, an automatic approach is unable to predict an accurate merge.
Another example of external context is updates to languages rules that have cascading effects on existing code. Participant P22 from the Roslyn project explained one such conflict: "Changes were due to updates in 'using' rules for the C# language". Language updates in C# version 8.0 introduced an alternative syntax for the using statement and P22's team had made to adopt this syntax. P22 therefore updated this code (involved in the conflict) during the merge. Other examples of external context identified through the survey include: removal of global dependencies from non-conflicting files within a project, rolling back features that shouldn't be included in a release branch, and project-level decisions to remove 'final' modifiers for variables.
Takeaway 3: The local view of a conflict is sufficient to merge a majority of conflicts. Around 16% of the conflicts require external information to correctly resolve. One direction to improve Merge-BERT is to consider external context as an additional information source for resolving conflicts. 9.2.3 Unacceptable Merge Suggestions. Survey results show that MERGEBERT suggestions were incorrect for 29% (36/122) of the conflicts. Participants indicated that none of the 36 conflicts required external context to be resolved. We manually analyze the conflicts looking to identify patterns that may explain the incorrect merges, for example, affected language construct (Pan, "Can Program Synthesis be Used to Learn Merge Conflict Resolutions? An Empirical Analysis") and type of conflict (Shen, "Automatic Detection and Resolution of Software Merge Conflicts"), but do not identify any consistent patterns. In summary, existing automatic evaluation strategies estimate a lower bound of approach performance: MergeBERT suggestions are correct for 54% of conflicts included in our sample, despite not being syntactically equivalent to the user resolution. Further, suggestions from Merge-BERT helped two participants find bugs in their own recent merge conflict resolutions! This is in addition to those resolutions where MergeBERT does provide an exact match. This finding suggests that automatic evaluation techniques that rely on a strict syntactic comparison between the user resolution and merge suggestion might be estimating a much lower bound of performance. This highlights a discrepancy between how approaches are typically automatically evaluated, and how developers may evaluate an approach in practice. Researchers should consider conducting user studies to more accurately evaluate approaches when feasible. Tools like MergeBERT can reduce effort and bug proneness involved in manually merging conflicts. Future studies should investigate these potential benefits.

## Related Work

There have been multiple attempts to improve merge algorithms by restricting them to a particular programming language or a specific type of applications (Mens, "A state-of-the-art survey on software merging"). Typically, such attempts result in algorithms that do not scale well or have low coverage. Syntactic merge algorithms improve upon diff3 by verifying the syntactic correctness of the merged programs. Several syntactic program merge techniques have been proposed (Asklund, "Identifying Conflicts During Structural Merge")(Westfechtel, "Structure-oriented merging of revisions of software documents") which are based on parse trees or ASTs and graphs.
Apel et al. noted that structured and unstructured merge each has strengths and weaknesses. They developed FSTMERGE, a semistructured merge, that alternates between approaches (Apel, "Semistructured Merge in Revision Control Systems"). Tavares et al. implemented JSFSTMERGE by adapting an off-the-shelf grammar for JavaScript to address shortcomings of FSTMERGE and also modifying the FSTMERGE algorithm itself (Tavares, "Semistructured merge in JavaScript systems"). Cavalcanti et al. performed a large scale retrospective evaluation of semi-structure merge on over 30,000 merges and found that it can still suffer from false negatives, cases where there is actually a semantic conflict but the merge approach produces a (incorrect) resolution (Cavalcanti, "Evaluating and improving semistructured merge"). They improve FSTMERGE by adding "handlers" that check for common false negative cases (e.g. renames, added references to modified elements) that remove these cases completely. LeÃŸenich noted that using AST representations works well for merge, but differencing is NP-hard due to renamings and shifted code. They propose an approach to improve performance of the JDIME algorithm at minimal cost (LeÃŸenich, "Renaming and shifted code in structured merging: Looking ahead for precision and performance"). Dinella et al. take a data driven approach to the merge conflict resolution problem and introduce DEEPMERGE, a deep neural network that uses a pointer network architecture to construct the resolution from lines in the different input versions of the code (Dinella, "DeepMerge: Learning to merge programs").
Finally, Sousa et al. (Sousa, "Verified Three-way Program Merge") explore the use of program verification to certify that a merge obeys a semantic correctness criteria, but does not help synthesize resolutions. On the other hand, Pan et al. (Pan, "Can Program Synthesis be Used to Learn Merge Conflict Resolutions? An Empirical Analysis") explore using program synthesis to learn repeated merge resolutions within a project. However, the approach is limited to a single C++ project, and only deals with restricted cases of import statements. 9.3.1 Empirical Studies. Several empirical studies have investigated merge conflicts and challenges faced by developers in merge resolution. McKee et al. (Mckee, "Software practitioner perspectives on merge conflicts and resolutions") and Nelson et al. (Nelson, "The life-cycle of merge conflicts: processes, barriers, and strategies") interviewed developers and performed a follow-up survey with 162 developers to build a detailed understanding of developer perceptions regarding merge conflicts in general. They found, among other things, that complexity of the conflicting lines of code and file as a whole, the number of LOC in the conflict, and developers' familiarity with the conflicting lines of code impact how difficult developers find a conflict to resolve. Brindescu et al. investigated the impact of merge conflicts and their resolutions on software quality (Brindescu, "An empirical investigation into merge conflicts and their effect on software quality")(Brindescu, "Lifting the Curtain on Merge Conflict Resolution: A Sensemaking Perspective"). They found that 20% of code changes resulted in a merge conflict and the code in these conflicts were twice as likely to contain bugs as other changes. Further, if the changes included semantically interacting changes, the likelihood of a defect is 26 times that of non-conflicting changes.
Costa et al. presented TIPMerge, an approach for identifying and recommending developers to participate in merge sessions when resolving conflicts (Costa, "Tipmerge: recommending experts for integrating changes across branches"). They evaluated it on 2,040 merges across 25 open source projects and found that TIPMerge can improve joint knowledge coverage by an average of 49% in merge scenarios (De, "Recommending Participants for Collaborative Merge Sessions").
Vale et al. (Vale, "Challenges of Resolving Merge Conflicts: A Mining and Survey Study") performed an empirical study to understand what makes merge challenging for developers. Through a large scale automated analysis and a survey of 140 developers, they identified factors that contribute to merge conflict resolution difficulty (e.g., number of chunks in the conflict and number of developers involved in the merge scenario). Seibt et al. (Seibt, "Leveraging Structure in Software Merge: An Empirical Study") explore and evaluate merge algorithms on a suite of ten software repositories, paying attention to the amount of resolutions produced, size of conflict, runtime cost, and correctness. Interestingly, they use the test suites of each project as an oracle to assess correctness of code after the merge.
None of the existing studies evaluate automatic merge resolution tools with software developers on their own real-world conflicts. The participants in our survey have expertise to understand when MergeBERT resolution suggestions would be acceptable on their own real-world conflicts, providing rich explanations about when external context is required, or when tangled code changes are made.

## THREATS TO VALIDITY

The choice of hyper-parameters in our model (Section 5.3) is based on prior work of others and generally accepted norms (Devlin, "BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding"). It's possible that exploring the hyper-parameter space could yield different results. The sample of conflicts and projects used in the study may pose a threat to the external validity of our work. We only considered public open-source projects hosted on GitHub, therefore, results may not generalize to closed source projects or repositories hosted on other platforms. To mitigate this threat, we select a diverse set of projects varying in size and language. Similarly, survey participants evaluate their own recently-merged conflicts and the set of conflicts used in the survey to answer RQ4 may not be a representative sample, as it was dependent on participant availability. We filtered out merge conflicts from the user study that we considered to be "trivial" conflicts. This was a subjective judgement, but we did aim to select substantive conflicts in the hopes that they would elicit more valuable and informative feedback from participants. The survey interface replicates the VSCode diff3 view. Participants not familiar with this view may have a harder time navigating the conflict view and answering survey questions, to mitigate this threat, we create an instructional video for participants to watch.

## CONCLUSION

This paper introduces MergeBERT, a transformer-based program merge framework that leverages token-level differencing and reformulates the task of generating the resolution sequence as a classification task over a set of primitive merge patterns extracted from real-world merge commit data. MergeBERT exploits pretraining over massive amounts of code and then finetuning on specific programming languages, achieving 64-69% precision and 63-68% recall of merge resolution synthesis. Lastly, MergeBERT is flexible and effective, capable of resolving more conflicts than the existing tools in multiple programming languages.
To better evaluate the resolutions generated by MergeBERT from the perspective of users, we conduct a user study with 25 developers from large OSS projects. We ask participants to evaluate whether MergeBERT resolution suggestions are acceptable on a set of 122 of their own real-world conflicts. Results suggest, in practice, Merge-BERT resolutions would likely be accepted at a higher rate than estimated by the performance metrics chosen. Using participant feedback we identify potential ways to improve MergeBERT by improving the oracle to remove tangled changes or considering external context -project or team level information that is not present in the conflicting files.
