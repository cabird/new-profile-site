# Empirical Software Engineering at Microsoft Research

**Abstract**

We describe the activities of the Empirical Software Engineering (ESE) group at Microsoft Research. We highlight our research themes and activities using examples from our research on socio technical congruence, bug reporting and triaging, and data-driven software engineering to illustrate our relationship to the CSCW community. We highlight our unique ability to leverage industrial data and developers and the ability to make near term impact on Microsoft via the results of our studies. We also present the collaborations our group has with academic researchers.

## INTRODUCTION

The Empirical Software Engineering (ESE) group at Microsoft Research focuses on working in the intersection of the Software Engineering and CSCW communities.
"Over the last decade, it has become clear that empirical studies are a fundamental component of software engineering research and practice: Software development practices and technologies must be investigated by empirical means in order to be understood, evaluated, and deployed in proper contexts. This stems from the observation that higher software quality and productivity have more chances to be achieved if well-understood, tested practices and technologies are introduced in software development. Empirical studies usually involve the collection and analysis of data and experience that can be used to characterize, evaluate and reveal relationships between software development deliverables, practices, and technologies." (Empirical Software Engineering journal, http://www.springer.com/computer/swe/journal/10664) At a high level the goals of the ESE follows two guiding principles,  Empower software development teams  To gain insight from product process, people and customers by employing a qualitative and quantitative approach to the software development process.
In this paper we discuss three broad themes of the ESE group,  Socio technical congruence;  Bug reporting and triaging; and  Data-driven software engineering.
In each of these sections our studies leverage techniques and methods from both the Software Engineering and CSCW communities to adapt case studies in practice from the empirical domain with the CSCW aspects as all software systems which are built by teams inherently have a significant collaborative aspect. We also present our collaborations and discuss the uniqueness of our fit in the middle of these two communities.

## SOCIO TECHNICAL CONGRUENCE

"Design and programming are human activities; forget that and all is lost" -Bjarne Stroustrop
As software projects grow in size and complexity, so do the teams of engineers that develop and maintain them. Brooks, in his seminal work, "The Mythical Man Month"
[1] discussed coordination as one of the key problems of running a software project with many developers. The coordination effort required to help each member of a team stay in sync and keep a project on schedule is enormous.
Socio Technical Congruence is a term that has emerged recently in the software engineering literature to describe the relationship between the "social" side of development, meaning the developers, their relationships to each other, how they communicate, work together on software, etc. and the "technical" side which encapsulates features of the software itself such as dependencies between components, component complexity, and software quality. The idea behind the term has its origins in Conway's Law, originally presented in Conway's paper "How Do Committees Invent" [2]. This is of importance to the CSCW community because of the emphasis placed on understanding how, and under what circumstances, developers should work together on projects.
In an effort to aid the development effort at Microsoft and understand the effect of human factors, we have gathered data and investigated the relationship of software quality with developer attributes such as collaboration behavior, geographic location, position within the organization, and work assignment. Below, we describe some of our key results.

## Contribution Behavior and Quality

Is a study of collaboration behavior, Nachi, in joint work with Martin Pinzger, developed a developer-module network, which characterized the contributions of developers to modules within a system (Pinzger, "Can developer-module networks predict failures?"). Figure 1 shows an example developer-module network. Gray circles represent developers and boxes represent modules within a system. Edges connect developers to the modules that they have contributed to, with edge weights representing the number of source code repository commits. Note that the developer-module network for Windows Vista is quite large, with thousands of developers and thousands of binaries -executables (.exe), shared libraries (.dll) and drivers (.sys).
We found that topological properties of this network were highly related to post-release faults. For instance, modules that were more central, as defined by traditional social network analysis centrality measures, tended to have more faults than other modules. We also found that less complex measures, such as the number of distinct authors and number of distinct commits were both significant predictors for the probability of post-release failures. By using a host of social network measures (we refer the reader to the original paper for details and descriptions) in conjunction with principal component analysis, we were able to train a logistic regression module for predicting failure-prone modules that achieved an average precision of 83% and recall of 89%. We summarize our important results:
 Network centrality measures can predict failureprone binaries in Windows Vista.  Network centrality measures can predict the number of post-release failures.
 Advanced centrality measures can improve the prediction of number of post-release failures.
In summary, we found that a strong relationship exists between the developers' commit behavior and the software quality of modules within the system.

## Adding Technical Relationships

In later work, Christian and Nachi built upon this result by adding module dependencies to the developer-module network (Bird, "Putting it All Together: Using Socio-Technical Networks to Predict Failures"). In previous work, Tom and Nachi found that dependencies can predict failures in both modules (Zimmermann, "Predicting Defects using Social Network Analysis on Dependency Graphs") and subsystems (Zimmermann, "Predicting subsystem failures using dependency graph complexities"). A network that incorporates both developer contributions and dependencies is a socio-technical network because edges may represent contributions from people to modules or dependencies between modules within a system. Figure 2 depicts a portion of a socio-technical network. Circles represent modules and boxes are developers. Solid directed edges are dependencies, indicating that one module may use functions or types defined in another, may make RPC calls to another, etc. Dashed lines indicate that a developer contributed to a module (we used weights in our analysis, but do not depict them in the figure).
By combining both types of relationships into one graph, we were able to increase the power of fault predicting regression models. Using principal component analysis, we found that models based on this network had higher recall than networks with only contribution edges (developermodule networks) or only dependency edges to a statistically significant degree in Vista (recall was similar to previous models).
To see if such models are specific to Microsoft or if they are more generally applicable, we also applied the same techniques to 6 major releases of the Eclipse Java IDE (2.0 through 3.3) and achieved precision and recall rates of failure-prone plug-ins ranging from 75% to 86%. Further, we were able to train a regression model on one release of Eclipse and achieve recall and precision values ranging from 75% to 93% on the next release, showing that cross release prediction works well for network based regression models. The key contributions of this work were:
 We found that using technical and contribution relationships together have more power than either in isolation for predicting bugs.  We showed that such techniques are general by using them on projects that differ in size, domain, and process (commercial vs. open source).  We demonstrated how such techniques can be used in practice to accurately predict failure prone modules in one release using data from a prior release.
In all of these models, the inclusion of developer behavior significantly improved the results over models that did not. Clearly, the human side of software engineering has a profound effect on quality.

## Does Organizational Structure Affect Bugs?

One of the unique advantages of working within an organization like Microsoft is that we have access to types of data that may not be available in academia. One such form of data is the organizational structure of the teams that develop the software.
Brooks stated that product quality is strongly affected by organization structure [?]. In order to empirically evaluate this claim, Nachi and a visiting researcher, Vic Basili, developed a suite of metrics to quantify organizational complexity (Nagappan, "The influence of organizational structure on software quality: an empirical case study") and investigated the relationship of these measures with software quality that we summarize below. The term "owning organization" is used to denote the organization that owns the binary.
 Number of engineers that worked on a binary  Number of engineers who worked on a binary and left the organization prior to release  Total number of contributions to a binary  Number of levels up the organization required to reach the person who oversees the engineers making at least 75% of the contributions to a binary  Proportion of engineers in the owning organization who contributed to a binary  Proportion of edits to a binary that were made by the owning organization  Ratio of proportion of engineers reporting to the owning manager relative to the total number of engineers editing a binary  Number of different organizations that contribute at least 10% of the edits to a binary Each of these measures is based on a hypothesis related to software quality. For instance, a large loss of team members (2 nd measure) affects knowledge retention and thus quality. The more cohesive the contributors are (organizationally, 5 th measure) the higher the quality.
We gathered these metrics for Windows Vista and correlated each with post-release faults in the first six months. We also evaluated the accuracy of a predictive model based on these metrics. Our results indicate that all eight measures are important because a step-wise regression retained every measure. We also created a predictor based on principal component analysis (due to high correlation between some measures) and compared it to prior approaches that included attributes such as code churn, code complexity, dependencies, code coverage during testing, and pre-release bugs. Surprisingly, the model based purely on organizational metrics performed better, in terms of precision and recall, than all of these models to a statistically significant degree.
We were able to build a better predictor using attributes of the organization that developed the software instead of using attributes of the software itself. This finding highlights the importance of coordination and collaboration in software development, as it implies that perhaps high levels of coordination are able maintain code quality in the face of factors known to result in faults such as higher levels of complexity or code churn.
Vista is a large project, in terms of code and developers. In an attempt to determine how large a project needs to be before these organizational measures begin to have an effect, we replicated our study on a smaller data set and found that a team size of 30 engineers and three levels of organizational depth should be sufficient for a model to predict failure-proneness.

## Investigating the Effects of Geographic Distribution

An additional form of information that we have related to software development is the geographic location of all developers. This enabled us to address an issue that many have wondered about and that may have consequences for Microsoft's development process, "Does distributed development affect software quality?"
In 2009, Chris and Nachi investigated this question by examining the locations of the developers that worked on each binary that shipped with Windows Vista (Bird, "Does Distributed Development Affect Software Quality? An Empirical Case Study of Windows Vista"). We grouped binaries into 6 categories depending on how spread out the developers were that contributed to them. Some binaries were developed mostly by developers in the same building while others had a team that spanned multiple countries.
When we compared the defect rates for the different groups, we found that no group had more than 16% more defects than binaries developed by engineers in the same building. While this is not a trivial increase, we had expected the effect of geographic distribution to be much larger due to the barriers imposed such as lack of familiarity, time zone issues, and less-rich communication. Following a similar type of analysis to that of Herbsleb and Mockus (Herbsleb, "An empirical study of speed and communication in globally distributed software development"), we examined the effects of distribution when controlling for team size. There was very little difference in failures, 6% at most, between distributed and collocated binaries.
We also examined attributes of the binaries in each group in order to determine if, for instance, managers only distributed binaries that were smaller, less critical to the system, or made up for distribution by testing more. In all, we exam-ined over 50 measures in categories such as complexity, churn, test coverage, dependencies, and organizational metrics, and determined that there is very little difference between distributed and collocated binaries other than team size. Thus, it appears that within Microsoft, distributed development doesn't negatively affect quality. There are a number of reasons that we believe this may be (and we invite the reader to examine them in the original paper (Bird, "Does Distributed Development Affect Software Quality? An Empirical Case Study of Windows Vista")), but we have yet to empirically verify them.
This result is all the more surprising in light of the findings of our study on organizational metrics, as it may seem to be at odds with those findings. The resolution of it lies in the fact that organizational structure spans geography at low levels within Microsoft. While some companies have an Asian organization, a European organization, etc., within Microsoft, it is not uncommon to have a team with developers in India and others in Beijing who report to a second line manager in Redmond. This approach may be one reason that geography has less of an effect, but we plan to study this further to provide more conclusive evidence.

## BUG REPORTING AND TRIAGING

In the past years, Tom
Zimmermann has collaborated with other researchers on studies on bug tracking systems. The advantage of these collaborations is that academic researchers can analyze open-source projects, while we can analyze projects at Microsoft. Thus findings come with a higher generality. Bug reports are a perfect data source for CSCW research. They capture collaboration, communication, and coordination among people. Especially in open source projects, bug tracking systems directly involve the users of a software and not just the engineers. This leads to communities of several thousand people who discuss and work towards a resolution of software bugs. In our research we studied bug tracking in open source and a closed source environments.. What Makes a Good Bug Report?
Tom, in joint work with Rahul Premraj, Nicolas Bettenburg, Sascha Just, Adrian Schröter, and Cathrin Weiss, conducted a survey among developers and users of the Apache, Eclipse, and Mozilla projects (Zimmermann, "What Makes a Good Bug Report? IEEE Transactions on Software Engineering. To appear"). The 466 responses revealed several interesting findings on how to improve bug tracking systems.
First, we observed a mismatch between the information considered most useful by developers and the information provided by reporters (see Figure 3). Developers want steps to reproduce, stack traces, and test cases in bug reports; however, this is not the information that reporters provide. Yet, when asked, the reporters' responses indicated that they know what is most helpful to developers and the rankings matched almost perfectly (see Figure 4). There are two implications for bug tracking systems: (1) Tell users while they are reporting a bug what information is important. (2) At the same time, systems should provide better tools to collect important information automatically, because often this information is difficult to obtain for users.
Next, we analyzed the comments by the survey respondents to identify additional design recommendations:
 Support different levels of users (novice, expert) and provide different user interfaces for each level. Inexperienced users should receive more guidance when reporting bugs.  Integrate bug report reputation. Several developers pointed out that reporters who are well known, either personally or through well-written past bug reports, will get more attention. Experienced reporters could be marked in their user profiles.  Provide a powerful, yet simple and easy-to-use search feature. Several respondents to our survey complaint about the limited search functionality, which is often only basic keyword search.
For a complete list of recommendations, we refer to our main publication on this work (Zimmermann, "What Makes a Good Bug Report? IEEE Transactions on Software Engineering. To appear").

## Reassignment of Bug Reports

Many people collaborate on fixing bugs and bug reports are often reassigned to other developers. Together with Gaeul Jeong and Sung Kim, Tom proposed bug tossing graphs (Jeong, "Improving bug triage with bug tossing graphs") to capture frequent reassignment patterns. In these graphs, nodes represent developers and weighted edges represent the number of reassignments between two developers.
On two large open-source projects, we showed that bug tossing graphs combined with Markov chains can reduce the number of reassignments substantially (also known as ticket routing problem (Shao, "Efficient ticket routing by resolution sequence mining")).
However, not all bug reassignments are necessarily bad. Sometimes reassignments are actually needed to locate the root cause for a bug and to find the right person who can fix the bug. Such "beneficial" reassignments can increase the chances of a bug report getting fixed (see next subsection). We are currently working on a characterization of bug report reassignments to identify potential improvements for bug tracking systems.

## Characterizing which Bugs Get Fixed

Often, the cost or risk of fixing a bug can be too high, or the impact of a bug report can be too low (only few people affected, easy workaround). Thus not all bug reports get fixed in real software development. In joint work, with Philip Guo, we characterized which bugs get fixed in Windows Vista and Windows 7 (Guo, "Characterizing and predicting which bugs get fixed: an empirical study of Microsoft Windows"). We made several observations related to how people collaborate and coordinate:
 People who have been more successful in getting their submitted bugs fixed are more likely to get their bugs fixed in the future.  Reassignments are not always detrimental to bugfix likelihood; several might be needed to find the optimal bug fixer.  Bugs assigned across teams or locations are less likely to get fixed, due to less communication and lowered trust.

## Collaboration and Information Needs in Bug Reports

Especially in open source, bug tracking systems play a central role in supporting collaboration between the developers and the users of the software. To better understand this collaboration, we quantitatively and qualitatively analyzed the questions asked in a sample of 600 bug reports from the MOZILLA and ECLIPSE projects (joint work with Silvia Breu, Rahul Premraj, and Jonathan Sillito) (Breu, "Information needs in bug reports: improving cooperation between developers and users").
We categorized the questions into a catalogue of frequently asked questions (eight categories, 40 subcategories) and then analyzed response rates and times by category and project. Key findings of this study include:
 Empirical analysis of response rate and time. Out of all questions, 67.66% were responded to. Of the questions with responses, 79.4% received responses within the day.  Evolving information needs. We learned that the kind of questions and thus the information needs change over a bug's life cycle.  Community-based bug tracking. Bug reporting and tracking should be understood as a social activity within a community, supported by the bug tracking system.
Our results showed that the role of users goes beyond simply reporting bugs: their active and ongoing participation is important for making progress on the bugs they report.
Based on the results, we suggested four ways in which bug tracking systems can be improved (see the main publication on this work (Breu, "Information needs in bug reports: improving cooperation between developers and users")).

## DATA-DRIVEN SOFTWARE ENGINEERING

A significant proportion of empirical research is done via case studies which collect and analyze data from software artifacts and the associated processes and variables to quantify, characterize and explore the relationship between different variables to deliver high quality secure software on time and within budget. Data-Driven Software Engineering forms a crucial part of empirical software engineering as it can be used to understand the successful development of software systems. Nachi Nagappan and Brendan Murphy were some of the first at Microsoft to begin collecting and analyzing software engineering artifact data for this purpose.
In this section we will explain three of our projects at a very high level that involve data driven software engineering. They range from software product to software practice issues. The three projects are, 1. Software product -Failure-prediction/Risk analysis: Using software development data obtained during the development process to predict failures and identify the best predictors. 2. Software practice -Does test-driven development work? If so is there any supporting data for teams to make decisions to use test-driven development. 3. Software practice -Is there data available on how effective Unit testing is? What is the cost associated with unit testing and do developers offer a resistance to unit testing.

## Failure-Prediction/Risk Analysis

An important application of data-driven software engineering is in the field of failure-prediction. Failure prediction can be used to understand the overall success of the development process and plan for maintenance activities. Software organizations can benefit greatly from an early estimation regarding the quality of their product. Because product quality information is available late in the process, corrective actions tend to be expensive (Boehm, "Software Engineering Economics").
During the development cycle different metrics can be collected that can be related to product quality. The goal is to use such metrics to make estimates of post-release failures early in the software development cycle, during the implementation and testing phases. Such estimates can for example help focus testing, code and design reviews and affordably guide corrective actions. Across a span of several years, Nachi and Brendan (in collaboration with others) have used different metrics for failure prediction: code coverage (Mockus, "Test coverage and post-verification defects: A multiple case study"); code churn (Nagappan, "Use of relative code churn measures to predict system defect density"); code complexity (Bhat, "Building Scalable Failureproneness Models Using Complexity Metrics for Large Scale Software Systems"); code dependencies (Nagappan, "Using Software Dependencies and Churn Metrics to Predict Field Failures: An Empirical Case Study"); people and organizational metrics (Nagappan, "The influence of organizational structure on software quality: an empirical case study").
Based on the results from using these various metrics either individually or in as a composite model effective failure prediction models have been built and is used in a wide variety of products at Microsoft. These failure-prediction models are built as services which allow engineers to predict risk; identify other engineers who share dependencies with their code which might be affected by changes; prioritize testing; identify ownership to have the best person fix bugs and plan for staffing up for maintenance activities.

## Test-Driven Development

Test-driven development (TDD) (Beck, "Test Driven Development: By Example") is an "opportunistic" software development practice that has been used sporadically for decades. With this practice, a software engineer cycles minute-by-minute between writing failing unit tests and writing implementation code to pass those tests. Testdriven development has recently re-emerged as a critical enabling practice of agile software development methodologies (Cockburn, "Agile Software Development"), in particular Extreme Programming (XP) (Beck, "Extreme Programming Explained: Embrace Change"). However, little empirical evidence supports or refutes the utility of this practice in an industrial context.
For this purpose, Nachi collected and analyzed (Bhat, "Evaluating the efficacy of test-driven development: industrial case studies") data from three different teams at Microsoft (in Windows, MSN and Visual Studio) to build up an empirical body of knowledge on the efficacy of TDD. This has enabled teams to decide on the utility of TDD as a development practice. Further, by documenting the contextual information about the human factors about the engineers involved (their experience, programming expertise, whether collocated or distributed) team can make a data-driven decision on their move to following a TDD for software development.

## Software Unit Testing

Unit testing is the testing of individual hardware or software units or groups of related units (IEEE (Ieee, "IEEE Standard 610.12-1990, IEEE Standard Glossary of Software Engineering Terminology")) and has been widely used in commercial software development for decades. But academic research has produced little empirical evidence via a large scale industrial case study on the experiences, costs, and benefits of unit testing. Does automated unit testing produce higher quality code?
To help other teams make a data-driven decision, Nachi, Laurie Williams, and Gunnar Kudrjavets observed (Williams, "On the Effectiveness of Unit Test Automation at Microsoft") one large Microsoft team consisting of 32 developers transitioned from ad hoc and individualized unit testing practices to the utilization of the NUnit automated unit testing framework by all members of the team. We quantified the quality and effort required to transition from the ad-hoc testing to a more formal unit testing process. Also to further quantify developer perceptions we conducted a survey and interviews with the team to determine the tradeoffs of doing unit testing. These results can help other teams decide on the cost and overhead to transition towards a more formal unit testing process.
In general the three projects in the data -drive software engineering domain are more focused towards the empirical data analysis with making the results accessible to engineers via tools, techniques and processes.

## Analytics for Software Development

The previous subsection presented studies where the ESE group collaborated with product teams at Microsoft. Our future work will focus on making data-driven software engineering accessible to a wider audience of engineers and managers.
We plan to build tools that allow an easy access to data to simplify data-driven decision making. For example, existing development environments such Microsoft's Team Foundation Server and IBM's Jazz provide dashboards to inform engineers of the status of various events. However, while showing status and indicators is fairly straightforward, it is unclear what are the most important factors are for development teams to make data-driven decisions. What do we need to surface so that development data becomes actionable for teams so that they can improve how they work together?
Furthermore, we plan to evangelize empirical methods in software development and will provide analytics tools to empower development teams to run studies that go beyond the use of simple dashboards. In particular, we foresee the role of a software development analyst who combines the expertise in collecting and analyzing data with the knowledge of processes specific to the product team. Right now, this expertise is often split across Microsoft Research (who have the analytics knowledge) and product teams (who have the domain knowledge).

## WHAT MAKES EMPIRICAL SOFTWARE ENGINEERING RESEARCH AT MICROSOFT UNIQUE?

An industrial research lab such as Microsoft Research has several advantages to conduct research.
Easy access to industrial data. During software development a large amount of data is generated and recorded in software repositories. Being inside Microsoft simplifies the access to such data and enables empirical studies as the ones presented in this paper.
Easy access to developers. Not only is the access to data easier, but also the access to engineers. This allows validation of empirical findings, user studies of prototypes, interviews, surveys, etc. and makes an ideal environment to study collaboration in software development.
Near term impact. Since Microsoft's core business is developing software, findings that result from our studies can b s q C p in m a s C o o w ic th r d r F ic lo a lo a t g ti a C I c s a a e F be put into prac serves to valida quality and pro Collaboration plenty opportu nside Microso more than 80 around the wor sible and allow Collaboration opportunities fo outside Micros we analyze dat c researcher an he generality o researchers also data either as researchers (for Figure 5 shows cal Software ocations. In th and 7 professo ooking for out about visits or tact one of the group members ime (Nachi Na and Christian B CONCLUSION In this paper, w case the researc sis of socio tec allows us to un and to build too er. With data-d Figure 5. Colla ctice immediat ate the findings ductivity. with other Mic unities to colla oft. At the mo 0 researchers, rld. For most a w for multidiscip with external for our group t soft. Often we ta from Micros nalyzes open-s of our empiric o get the oppo interns (typica r example, pro s a Bing map w Engineering G he past years w ors from all ov tstanding visito r internships v e authors of t s interned befo agappan in 200 Bird in 2008 an we presented ch of the ESE chnical congru nderstand how d ols that help th driven software aborations of t tely within the s and results in crosoft researc aborate with o oment Microso , working in areas, experts a plinary researc researchers. T to collaborate e conduct rese soft projects, w source projects al findings. Se ortunity to acc ally PhD stud fessors during with the locatio Group and th we have worke ver the world. ors and interns. visit our web-s this paper. In ore they joined 05, Tom Zimm nd 2009) three main the group at Micr ence and bug t development te hem collaborat e engineering, the Empirical e company. Th n higher levels chers. There a other researche oft Research h eight locatio are easily acce ch when needed There are man with researche earch in tandem while an academ s. This increas elected academ ess to Microso ents) or visitin a sabbatical). ons of the Empi he collaborator ed with 8 inter We are alwa . To learn mo site and/or co fact, three ES d Microsoft fu mermann in 200 emes that show rosoft: the anal tracking system eams collabora te with each ot we want to tak Software Eng his of are ers has ns esd. ny ers m: mses mic oft ng irr's rns ays re n-SE ull-06, wlyms ate thke this on knowle themse Being opportu softwa ent. R ing (lik field d pens. cooper needed For m and/or h ACKNO We tha visitors William Basili our int Kalaik Tosun (both 2 the gre We als many p us and REFER 1. Bro We 2. Co 14, gineering and ne step further edge and tools elves and moni located inside tunities to purs are projects and Rather than just ke many studi do), we can wat We can also t rative work a d and when eng more informatio to apply for an http://research.m OWLEDGMEN ank Tom Ball s Sung Kim (2 ms (2009), An (2007), Neera terns Ray Bus kumaran Rama (both 2009), 2007); and we eat work! so thank our co product group helped with st RENCES ooks Jr., F.P. T esley, 1975. onway, M.E. H , 4 (1968), 28-Main location Redmond (US Collaboration Microsoft Res Asia (Beijing) (Aachen, Germ Interns 2007-University of National Instit (Kalaikumaran (Philip Guo); Darmstadt Un North Carolin Meiyappan Na Visitors 2007 Technology (S Martin Pinzge North Carolin University of University of Measurement r: developmen s to analyze the itor their impro Microsoft off ue our goals. M d the "coopera t coming in afte ies in the mini tch software d test tools relat and understan gineers can wo on about the E n internship, lo microsoft.com/ NTS , Robin Moeu 2010), Harald G ndreas Zeller aj Suri (2007), se, Ken Hullet amurthy (all 2 , Lucas Laym e thank our co olleagues at Mi ps at Microsoft tudies. You roc The mythical m How do commit 31. ns of the ESM gr SA), Cambridge ( ns with other Mi search India (Ban ), European Micro many) -2010: University California, Santa tute of Technolog n Ramamurthy); Boğaziçi Univers niversity of Techn na State University agappan) 7-2010: Hong Kon Sung Kim); Univ er); Saarland Univ na State University Maryland (Victor Technology (Nee t (ESM) Group nt teams should eir collaboratio ovement over t fers us with ma Microsoft has m ative" aspect is er the fact and ing software r development wh ted to helping nd when coop ork on their ow ESE group at ogon to /en-us/projects ur, Wolfram Sc Gall (2008, 200 (2005, 2009), , Martin Pinzg tt, Meiyappan 2010), Philip G man, Andreas ollaborators. T icrosoft Resear ft who have wo ck! man-month. Ad ttees invent. Da roup (black pins (UK) icrosoft Researc ngalore), Microso osoft Innovation y of Virginia (Ray a Cruz (Ken Hulle gy, Tiruchirappal Stanford Univers sity, Turkey (Ays nology (Andreas J y (Lucas Layman ng University of versity of Zurich ( versity (Andreas y (Laurie William r Basili); Darmst eraj Suri). p at Microsoft d have the on patterns time. any unique many large s omnipresinvestigatrepositories hile it hapto support peration is wn. Microsoft s/esm/ chulte; our 09), Laurie Victor R. ger (2007); Nagappan Guo, Ayse Johansson Thanks for rch and the orked with ddisonatamation, s): ch Labs: oft Research Center y Buse); ett); lli, India sity se Tosun); Johansson); n, Science and (Harald Gall, Zeller); ms); adt Research.
